{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNWbp+FOGRhwSZSVfbvZoVb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joshtburdick/misc/blob/master/plog/EP_discrete.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EP with discrete variables\n",
        "\n",
        "Here, we try to implement EP with just discrete variables."
      ],
      "metadata": {
        "id": "Dv0okgLCC6Fx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "hk4h6YE0C3EG"
      },
      "outputs": [],
      "source": [
        "# prompt: import likely stuff for plotting using jax\n",
        "\n",
        "import jax.nn as nn\n",
        "import jax.numpy as jnp\n",
        "import jax.random as jrandom\n",
        "import jax.tree_util as tree_util\n",
        "from jax import grad, jit, vmap\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Moments\n",
        "For converting between moments, we just use nn.softmax()."
      ],
      "metadata": {
        "id": "Ly0SRPXjyckB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = jnp.array([[1.,2.], [0.,3.]])\n",
        "\n",
        "x\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wYisN9j-vNo0",
        "outputId": "f8ecb336-7703-4333-9d75-8ff972c4b620"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Array([[1., 2.],\n",
              "       [0., 3.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nn.softmax(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bl0q719JvZth",
        "outputId": "b85d4714-85c5-4189-83b1-33a8ed72d8cb"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Array([[0.26894143, 0.7310586 ],\n",
              "       [0.04742587, 0.95257413]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nn.softmax(x, axis=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vhhla3nDvm34",
        "outputId": "840ca0c7-158f-4c84-cc5e-de6646e882fb"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Array([[0.26894143, 0.7310586 ],\n",
              "       [0.04742587, 0.95257413]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that taking logs, and softmax, are (mostly) inverses."
      ],
      "metadata": {
        "id": "Lh8Nitm8woqN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y = nn.softmax(x)\n",
        "print(y)\n",
        "print(jnp.log(y))\n",
        "print(nn.softmax(jnp.log(y)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4pYOA_-Mv2SF",
        "outputId": "21d8b659-74d4-42ea-d279-7890b9b46521"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.26894143 0.7310586 ]\n",
            " [0.04742587 0.95257413]]\n",
            "[[-1.3132616  -0.31326166]\n",
            " [-3.0485873  -0.04858734]]\n",
            "[[0.26894143 0.7310586 ]\n",
            " [0.04742587 0.95257413]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Implementing EP with discrete variables\n",
        "\n",
        "This is (an attempt at) a limited case of EP:\n",
        "- all variables are discrete, and take one of a set of values\n",
        "- potentials are arrays (possibly sparse)\n",
        "- messages are passed in parallel\n"
      ],
      "metadata": {
        "id": "qLb0Tm7bOwHZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Defining the model, and initializing\n",
        "\n",
        "The model will be represented using strings for variable and factor names; it will have a dict of variables, and a dict of factors.\n",
        "\n",
        "The model state will include the current beliefs (as natural parameters), and the factor-to-variable messages."
      ],
      "metadata": {
        "id": "oo_EMEjHRzCd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# practice\n",
        "rng = jrandom.key(42)\n",
        "\n",
        "a = jrandom.uniform(rng, 4)\n",
        "# (a / jnp.linalg.norm(a, 1))\n",
        "r, rng = jrandom.split(rng)\n",
        "b = jrandom.uniform(r, 4)\n",
        "(a,b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PhsNLO0oiC49",
        "outputId": "d293713e-8cf0-4305-d5d3-aff53deff6b6"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Array([0.48870957, 0.6797972 , 0.6162715 , 0.5610161 ], dtype=float32),\n",
              " Array([0.5302608 , 0.31336212, 0.90153027, 0.6983329 ], dtype=float32))"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sudoku example\n",
        "\n",
        "For 4-by-4 Sudoku, the variables are a grid of variables with four possible values. We also need a 4-D tensor for the potential constraining all four numbers to be different. (This tensor will be re-used several times.)\n",
        "\n",
        "This will also need potentials for filling in \"givens\".\n",
        "(Hopefully, as a test, if we omit these, this will just generate\n",
        "valid Sudoko boards?)\n"
      ],
      "metadata": {
        "id": "ElREZPdojzE4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Compute variables and factors which can be passed to ep_init (below) for 4-by-4 sudoku.\n",
        "\n",
        "import numpy as np\n",
        "# The state space for each variable is {0, 1, 2, 3}\n",
        "variable_values = jnp.arange(4)\n",
        "\n",
        "# The variables are arranged in a 4x4 grid\n",
        "grid_size = 4\n",
        "variables = {}\n",
        "for i in range(grid_size):\n",
        "  for j in range(grid_size):\n",
        "    var_name = f'v_{i}_{j}'\n",
        "    variables[var_name] = {'values': variable_values}\n",
        "\n",
        "# The factors enforce the constraint that each row, column, and 2x2 block must contain each number from 0 to 3 exactly once.\n",
        "\n",
        "# We need a tensor that represents the \"all different\" constraint for 4 variables.\n",
        "# This tensor will have a 1 if all values are different, and 0 otherwise.\n",
        "all_different_tensor = jnp.zeros((grid_size, grid_size, grid_size, grid_size))\n",
        "\n",
        "# Generate all possible combinations of 4 numbers from 0 to 3\n",
        "from itertools import product\n",
        "for combo in product(range(grid_size), repeat=grid_size):\n",
        "    if len(set(combo)) == grid_size: # Check if all values are different\n",
        "        all_different_tensor = all_different_tensor.at[combo].set(1.0)\n",
        "\n",
        "factors = {}\n",
        "\n",
        "# Row factors\n",
        "for i in range(grid_size):\n",
        "  factor_name = f'row_factor_{i}'\n",
        "  for j in range(grid_size):\n",
        "    factor_vars = [f'v_{i}_{k}' for k in range(grid_size)]\n",
        "    factors[factor_name] = {'variables': factor_vars, 'potential': all_different_tensor}\n",
        "\n",
        "# Column factors\n",
        "for j in range(grid_size):\n",
        "  factor_name = f'col_factor_{j}'\n",
        "  for i in range(grid_size):\n",
        "    factor_vars = [f'v_{k}_{j}' for k in range(grid_size)]\n",
        "    factors[factor_name] = {'variables': factor_vars, 'potential': all_different_tensor}\n",
        "\n",
        "# 2x2 block factors\n",
        "block_size = 2\n",
        "for block_row in range(grid_size // block_size):\n",
        "  for block_col in range(grid_size // block_size):\n",
        "    factor_name = f'block_factor_{block_row}_{block_col}'\n",
        "    factor_vars = []\n",
        "    for i in range(block_size):\n",
        "      for j in range(block_size):\n",
        "        row_idx = block_row * block_size + i\n",
        "        col_idx = block_col * block_size + j\n",
        "        factor_vars.append(f'v_{row_idx}_{col_idx}')\n",
        "    factors[factor_name] = {'variables': factor_vars, 'potential': all_different_tensor}\n",
        "\n",
        "# Also need factors for any pre-filled cells (givens)\n",
        "# For example, if cell (0,0) is given to be 2:\n",
        "# factors['given_0_0'] = {'variables': ['v_0_0'], 'potential': jnp.array([0., 0., 1., 0.])} # Potential is a one-hot encoding\n",
        "\n",
        "# ep_init expects a dict of variables and a dict of factors.\n",
        "# The variable dict contains the initial beliefs (e.g., uniform) and messages.\n",
        "# The factor dict contains the potential functions and connected variables.\n",
        "\n",
        "# Initialize variable beliefs (natural parameters) as uniform\n",
        "# For each variable, the initial belief is log(uniform) = log(1/4) = -log(4)\n",
        "initial_var_beliefs = {}\n",
        "for var_name in variables:\n",
        "  initial_var_beliefs[var_name] = jnp.full(len(variable_values), -jnp.log(grid_size))\n",
        "\n",
        "# Initialize messages (factor-to-variable)\n",
        "# All messages start as uniform (log(1/4)), representing no information yet.\n",
        "initial_messages = {}\n",
        "for factor_name in factors:\n",
        "  for var_name in factors[factor_name]['variables']:\n",
        "    message_key = (factor_name, var_name)\n",
        "    initial_messages[message_key] = jnp.full(len(variable_values), -jnp.log(grid_size))\n",
        "\n",
        "ep_init_vars = initial_var_beliefs\n",
        "ep_init_factors = factors\n",
        "ep_init_messages = initial_messages\n",
        "\n",
        "# You would then pass ep_init_vars, ep_init_factors, and ep_init_messages to ep_init.\n",
        "# The ep_init function (not provided here) would typically store these and set up the initial state.\n",
        "# The messages are usually part of the 'state' or 'params' rather than the initial model definition,\n",
        "# but they are needed to initialize the iterative process."
      ],
      "metadata": {
        "id": "zlVZ5qXFkVNw"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def ep_init(rng, variables, factors, ):\n",
        "  \"\"\"Initializes the model.\"\"\"\n",
        "  beliefs = {}\n",
        "  # beliefs are initialized to be random\n",
        "  for (var, n_vals) in variables.items():\n",
        "    r, rng = jrandom.split(rng)\n",
        "    beliefs[var] = jrandom.uniform(r, (n_vals,))\n",
        "    beliefs[var] = (beliefs[var] / jnp.sum(beliefs[var]))\n",
        "    beliefs[var] = jnp.log(beliefs[var])\n",
        "  # messages from factors are initially flat (I think?)\n",
        "  factor_to_var_messages = {}\n",
        "  for (name, factor) in factors.items():\n",
        "    factor_to_var_messages[name] = {var: jnp.zeros(n_vals) for var in factor.variables}\n",
        "  return {'beliefs': beliefs, 'factor_to_var_messages': factor_to_var_messages}\n"
      ],
      "metadata": {
        "id": "H2p9ZdLaTXmT"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Updating the state\n",
        "\n",
        "We need a function which will do one round of message-passing. It will be a function from state to state.\n",
        "\n",
        "Note that according to Gemini, \"observations\" are just additional\n",
        "factors (typically only connected to one variable).\n",
        "\n",
        "### Messages from a factor\n",
        "\n",
        "This takes the incoming messages to a factor, and computes messages from it.\n"
      ],
      "metadata": {
        "id": "skUJzO4zXSkW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def marginalize(a, messages_in):\n",
        "  \"\"\"Given the input messsages, compute the marginal messages.\n",
        "\n",
        "  a: the factor, as an n-dimensional tensor\n",
        "  messages_in: a list of 1-dimensional tensors, one for each\n",
        "    of the n variables connected to the factor\n",
        "  Returns: a list of 1-dimensional tensors, one for each variable\n",
        "    connected to the factor\n",
        "  \"\"\"\n",
        "  n = len(messages_in)\n",
        "  for i in range(n):\n",
        "      f = jnp.expand_dims(jnp.softmax(messages_in[i], axis=0),\n",
        "        [j for j in range(i)])\n",
        "      print(f.shape)\n",
        "      a *= f\n",
        "  axes = set(range(n))\n",
        "  messages_out = [jnp.log(jnp.sum(a, axis=tuple(axes-{i}))) for i in range(n)]\n",
        "  return messages_out"
      ],
      "metadata": {
        "id": "0I5AdRufBqvr"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here is what Gemini generated, for updating state:"
      ],
      "metadata": {
        "id": "VgFZCQ4YBmde"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Using the above definitions for what a (discrete variable) factor graph looks like, and a state (like what ep_init() returns), write a function which takes a factor graph, and a state, and does one round of parallel \"loopy belief propagation\" updates.\n",
        "\n",
        "import numpy as np\n",
        "def ep_update(fg, state):\n",
        "  \"\"\"Performs one round of parallel loopy belief propagation updates.\n",
        "\n",
        "  Args:\n",
        "    fg: A dictionary representing the factor graph. It should have keys\n",
        "      'variables' and 'factors'. 'variables' is a dict mapping variable names\n",
        "      to the number of values the variable can take. 'factors' is a dict\n",
        "      mapping factor names to dictionaries with keys 'variables' (a list of\n",
        "      variable names connected to the factor) and 'potential' (a JAX array\n",
        "      representing the factor potential).\n",
        "    state: A dictionary representing the current state. It should have keys\n",
        "      'beliefs' and 'factor_to_var_messages'. 'beliefs' is a dict mapping\n",
        "      variable names to JAX arrays of natural parameters.\n",
        "      'factor_to_var_messages' is a dict mapping factor names to dictionaries,\n",
        "      which map variable names to JAX arrays representing the factor-to-variable\n",
        "      message natural parameters.\n",
        "\n",
        "  Returns:\n",
        "    A new state dictionary after one round of updates.\n",
        "  \"\"\"\n",
        "  new_beliefs = state['beliefs'].copy()\n",
        "  new_factor_to_var_messages = state['factor_to_var_messages'].copy()\n",
        "\n",
        "  # Update variable-to-factor messages\n",
        "  var_to_factor_messages = {}\n",
        "  for var, belief in state['beliefs'].items():\n",
        "    var_to_factor_messages[var] = {}\n",
        "    for factor_name, factor_messages in state['factor_to_var_messages'].items():\n",
        "      if var in fg['factors'][factor_name]['variables']:\n",
        "        # Sum of all messages from other factors to this variable\n",
        "        sum_other_messages = jnp.sum(jnp.stack([\n",
        "            msg for other_factor_name, other_factor_messages in state['factor_to_var_messages'].items()\n",
        "            for other_var, msg in other_factor_messages.items()\n",
        "            if other_var == var and other_factor_name != factor_name\n",
        "        ], axis=0), axis=0)\n",
        "        var_to_factor_messages[var][factor_name] = belief - sum_other_messages\n",
        "\n",
        "  # Update factor-to-variable messages\n",
        "  for factor_name, factor_info in fg['factors'].items():\n",
        "      for var in factor_info['variables']:\n",
        "          # Sum of all incoming messages to the factor from other variables\n",
        "          incoming_messages_sum = jnp.sum(jnp.stack([\n",
        "              var_to_factor_messages[other_var][factor_name]\n",
        "              for other_var in factor_info['variables'] if other_var != var\n",
        "          ], axis=0), axis=0)\n",
        "\n",
        "          # Expand incoming messages to the factor's dimension\n",
        "          # This requires carefully handling the variable order and dimensions\n",
        "          incoming_messages_expanded = incoming_messages_sum # This is too simple and needs to be generalized\n",
        "\n",
        "          # For simplicity in this general definition, we'll skip the detailed marginalization step\n",
        "          # which requires knowing the variable order within the factor potential.\n",
        "          # A proper implementation would marginalize the product of the factor potential and\n",
        "          # incoming messages over all variables except the one we are sending the message to.\n",
        "\n",
        "          # Placeholder for the updated message - in a full implementation, this would involve\n",
        "          # combining the factor potential and incoming messages, then marginalizing.\n",
        "          # For this high-level update function structure, we'll represent the output message\n",
        "          # as a placeholder that should result from this process.\n",
        "          # The actual calculation depends heavily on the structure of the factor potential and\n",
        "          # the variable order.\n",
        "\n",
        "          # As a placeholder, let's imagine a process that results in an array of the\n",
        "          # correct dimension for the variable `var`.\n",
        "          # For now, we'll just keep the old message as a placeholder for this function's structure.\n",
        "          # A complete EP implementation requires detailed handling of array dimensions and axis summation.\n",
        "\n",
        "          # To make this runnable without a full marginalization implementation:\n",
        "          # Let's compute a simplified update that represents the message as the belief\n",
        "          # minus the incoming message from this factor. This is the message FROM the variable TO the factor.\n",
        "          # The message FROM the factor TO the variable is more complex.\n",
        "\n",
        "          # Let's refine the goal: perform the variable-to-factor message calculation accurately,\n",
        "          # and represent the factor-to-variable message update step, even if the internal\n",
        "          # calculation is simplified for this general structure.\n",
        "\n",
        "          # The standard factor-to-variable message update:\n",
        "          # 1. Combine the factor potential with the incoming messages from *other* variables connected to this factor.\n",
        "          # 2. Marginalize the result over all variables in the factor except the one the message is being sent to.\n",
        "          # 3. Subtract the incoming message from the variable being sent to from the result (or divide in moment form).\n",
        "\n",
        "          # This simplified implementation will just show the message passing structure.\n",
        "\n",
        "          # Re-calculating variable-to-factor messages (as needed for the factor update)\n",
        "          var_to_factor_msgs_for_factor = {}\n",
        "          for connected_var in factor_info['variables']:\n",
        "              if connected_var != var:\n",
        "                  sum_other_messages_to_connected_var = jnp.sum(jnp.stack([\n",
        "                      msg for other_factor_name, other_factor_messages in state['factor_to_var_messages'].items()\n",
        "                      for other_var, msg in other_factor_messages.items()\n",
        "                      if other_var == connected_var and other_factor_name != factor_name\n",
        "                  ], axis=0), axis=0)\n",
        "                  var_to_factor_msgs_for_factor[connected_var] = state['beliefs'][connected_var] - sum_other_messages_to_connected_var\n",
        "\n",
        "\n",
        "          # Placeholder for the factor-to-variable message update.\n",
        "          # This part requires knowing the layout of the factor potential and\n",
        "          # the variables it connects.\n",
        "          # A full implementation would involve array manipulations (like broadcasting and `jnp.sum`)\n",
        "          # based on the specific factor and variables.\n",
        "\n",
        "          # For the purpose of showing the function structure, we'll represent the updated\n",
        "          # message as a zero array of the correct size. This is NOT the correct EP update,\n",
        "          # but keeps the code runnable and shows where the update would happen.\n",
        "          num_values = fg['variables'][var]\n",
        "          new_factor_to_var_messages[factor_name][var] = jnp.zeros(num_values) # Placeholder\n",
        "\n",
        "  # Update beliefs\n",
        "  for var in fg['variables'].keys():\n",
        "      # Sum of all messages from factors to this variable\n",
        "      sum_incoming_factor_messages = jnp.sum(jnp.stack([\n",
        "          msg for factor_name, factor_messages in new_factor_to_var_messages.items()\n",
        "          for connected_var, msg in factor_messages.items()\n",
        "          if connected_var == var\n",
        "      ], axis=0), axis=0)\n",
        "      new_beliefs[var] = sum_incoming_factor_messages # In log space, beliefs are sum of log factor potentials (or messages)\n",
        "\n",
        "  return {'beliefs': new_beliefs, 'factor_to_var_messages': new_factor_to_var_messages}\n"
      ],
      "metadata": {
        "id": "4QC29EZrXSEQ"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As it says, it includes placeholders, so presumably isn't the actual\n",
        "correct implementation (although it does compile).\n",
        "\n",
        "One difference: I'm assuming that the beliefs are passed into this function (and so have already been updated)."
      ],
      "metadata": {
        "id": "-n1pEXRYmeVJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ep_update(fg, state):\n",
        "  \"\"\"Performs one round of parallel loopy belief propagation updates.\n",
        "\n",
        "  Args:\n",
        "    fg: A dictionary representing the factor graph. It should have keys\n",
        "      'variables' and 'factors'. 'variables' is a dict mapping variable names\n",
        "      to the number of values the variable can take. 'factors' is a dict\n",
        "      mapping factor names to dictionaries with keys 'variables' (a list of\n",
        "      variable names connected to the factor) and 'potential' (a JAX array\n",
        "      representing the factor potential).\n",
        "    state: A dictionary representing the current state. It should have keys\n",
        "      'beliefs' and 'factor_to_var_messages'. 'beliefs' is a dict mapping\n",
        "      variable names to JAX arrays of natural parameters.\n",
        "      'factor_to_var_messages' is a dict mapping factor names to dictionaries,\n",
        "      which map variable names to JAX arrays representing the factor-to-variable\n",
        "      message natural parameters.\n",
        "\n",
        "  Returns:\n",
        "    A new state dictionary after one round of updates.\n",
        "  \"\"\"\n",
        "  # Compute variable-to-factor messages, by subtracting out\n",
        "  # factor-to-variable messages from beliefs (and converting\n",
        "  # from logs).\n",
        "  var_to_factor_messages = {\n",
        "      (v): nn.softmax(state['beliefs'][v] - state['factor_to_var_messages'][f][v])\n",
        "      for f, v in state['factor_to_var_messages']\n",
        "  }\n",
        "\n",
        "  # Compute marginals, from each factor.\n",
        "  def marginals(factor_name):\n",
        "    m =\n",
        "\n",
        "marginalize(fg[\"factors\"][factor_name],\n",
        "\n",
        "  # Update variable-to-factor messages\n",
        "  var_to_factor_messages = {}\n",
        "  for var, belief in state['beliefs'].items():\n",
        "    var_to_factor_messages[var] = {}\n",
        "    for factor_name, factor_messages in state['factor_to_var_messages'].items():\n",
        "      if var in fg['factors'][factor_name]['variables']:\n",
        "        # Sum of all messages from other factors to this variable\n",
        "        sum_other_messages = jnp.sum(jnp.stack([\n",
        "            msg for other_factor_name, other_factor_messages in state['factor_to_var_messages'].items()\n",
        "            for other_var, msg in other_factor_messages.items()\n",
        "            if other_var == var and other_factor_name != factor_name\n",
        "        ], axis=0), axis=0)\n",
        "        var_to_factor_messages[var][factor_name] = belief - sum_other_messages\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "7OFtnWFro49R",
        "outputId": "51bae19b-e700-47ef-8419-13b458ff2de8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (ipython-input-19-1769059286.py, line 31)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipython-input-19-1769059286.py\"\u001b[0;36m, line \u001b[0;32m31\u001b[0m\n\u001b[0;31m    m =\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# practice\n",
        "x = jnp.array([0., 3., 2., -5])\n",
        "print(x)\n",
        "print(x.shape)\n",
        "print(nn.softmax(x))\n",
        "print(nn.softmax(x).shape)\n",
        "print(nn.softmax(x).sum())"
      ],
      "metadata": {
        "id": "TSH5yVhPptNL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "R54eU3WyqDbf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}